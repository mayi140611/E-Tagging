{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, time, random\n",
    "from utils import str2bool, get_logger, get_entity\n",
    "from data import random_embedding,tag2label\n",
    "import datapreprocessing as dp\n",
    "from model import BiLSTM_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Session configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # default: 0\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2  # need ~700MB GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths setting\n",
    "paths = {}\n",
    "timestamp='1529463214'\n",
    "output_path = os.path.join('.', 'data_path'+\"_save\", timestamp)\n",
    "if not os.path.exists(output_path): os.makedirs(output_path)\n",
    "summary_path = os.path.join(output_path, \"summaries\")\n",
    "paths['summary_path'] = summary_path\n",
    "if not os.path.exists(summary_path): os.makedirs(summary_path)\n",
    "model_path = os.path.join(output_path, \"checkpoints/\")\n",
    "if not os.path.exists(model_path): os.makedirs(model_path)\n",
    "ckpt_prefix = os.path.join(model_path, \"model\")\n",
    "paths['model_path'] = ckpt_prefix\n",
    "result_path = os.path.join(output_path, \"results\")\n",
    "paths['result_path'] = result_path\n",
    "if not os.path.exists(result_path): os.makedirs(result_path)\n",
    "log_path = os.path.join(result_path, \"log.txt\")\n",
    "paths['log_path'] = log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 1234\n"
     ]
    }
   ],
   "source": [
    "## get char embeddings\n",
    "word2id = dp.loadVocab('word2id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('pretrain_embedding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= demo =============\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your sentence:\n",
      "患者自述近几天病情有反复，睡眠差，需要吃助眠药物，情绪显低，不愿意做事。\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'B-ZS', 'I-ZS', 'I-ZS', 0, 0, 0, 0, 'B-YW', 'I-YW', 'I-YW', 'I-YW', 0, 'B-ZS', 'I-ZS', 'I-ZS', 'I-ZS', 0, 'B-ZS', 'I-ZS', 'I-ZS', 'I-ZS', 'I-ZS', 0]\n",
      "ZS: ['睡眠差', '情绪显低', '不愿意做事']\n",
      "Please input your sentence:\n",
      "病情稳定，夜眠差，服药后未见躯体不适及药物不良反应，要求继续配药。\n",
      "[0, 0, 0, 0, 0, 'B-ZS', 'I-ZS', 'I-ZS', 0, 'B-ZL', 'I-ZL', 0, 0, 0, 'B-1ZS', 'I-1ZS', 'I-1ZS', 'I-1ZS', 0, 'B-1ZS', 'I-1ZS', 'I-1ZS', 'I-1ZS', 'I-1ZS', 'I-1ZS', 0, 0, 0, 0, 0, 'B-ZL', 'I-ZL', 0]\n",
      "ZS: ['夜眠差']\n",
      "Please input your sentence:\n",
      "有糖尿病史多年，目前无口渴，无多尿，无多食等症状。今药服完配药。\n",
      "[0, 'B-B', 'I-B', 'I-B', 'I-B', 0, 0, 0, 0, 0, 0, 'B-1ZS', 'I-1ZS', 0, 0, 'B-1ZS', 'I-1ZS', 0, 0, 'B-1ZS', 'I-1ZS', 0, 0, 0, 0, 0, 0, 0, 0, 'B-ZL', 'I-ZL', 0]\n",
      "ZS: []\n",
      "Please input your sentence:\n",
      "患者三周无明显诱因下出现心悸、胸闷，无胸痛、气急等不适，面色黧黑，胃纳可，二便调，夜寐安。\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'B-ZS', 'I-ZS', 0, 'B-ZS', 'I-ZS', 0, 0, 'B-1ZS', 'I-1ZS', 0, 'B-1ZS', 'I-1ZS', 0, 0, 0, 0, 'B-YC', 'I-YC', 'I-YC', 'I-YC', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ZS: ['心悸', '胸闷']\n",
      "Please input your sentence:\n",
      "时有咳嗽、咳痰,无胸痛、咯血等，慢性支气管炎病史。哮喘病史，关节痛病史，外出提前配药\n",
      "[0, 0, 'B-ZS', 'I-ZS', 0, 'B-ZS', 'I-ZS', 0, 0, 'B-1ZS', 'I-1ZS', 0, 'B-1ZS', 'I-1ZS', 0, 0, 'B-B', 'I-B', 'I-B', 'I-B', 'I-B', 'I-B', 'I-B', 'I-B', 0, 'B-B', 'I-B', 'I-B', 'I-B', 0, 'B-B', 'I-B', 'I-B', 'I-B', 'I-B', 0, 0, 0, 0, 0, 'B-ZL', 'I-ZL']\n",
      "ZS: ['咳嗽', '咳痰']\n",
      "Please input your sentence:\n",
      "\n",
      "See you next time!\n"
     ]
    }
   ],
   "source": [
    "## demo\n",
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF(embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    print('============= demo =============')\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    while(1):\n",
    "        print('Please input your sentence:')\n",
    "        demo_sent = input()\n",
    "        if demo_sent == '' or demo_sent.isspace():\n",
    "            print('See you next time!')\n",
    "            break\n",
    "        else:\n",
    "            demo_sent = list(demo_sent.strip())\n",
    "            demo_data = [(demo_sent, ['O'] * len(demo_sent))]\n",
    "            tag = model.demo_one(sess, demo_data)\n",
    "            print(tag)\n",
    "            ZS = get_entity(tag, demo_sent)\n",
    "            print('ZS: {}'.format(ZS))\n",
    "#             PER, LOC, ORG = get_entity(tag, demo_sent)\n",
    "#             print('PER: {}\\nLOC: {}\\nORG: {}'.format(PER, LOC, ORG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= demo =============\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    print('============= demo =============')\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    corpus_dir = 'D:\\\\Desktop\\\\产品\\\\辅诊\\\\cndata\\\\ru1_tb_cis_mzdzbl\\\\tt'\n",
    "    for s in os.listdir(corpus_dir):\n",
    "        if s.endswith('.csv'):\n",
    "            with open(os.path.join(corpus_dir,s),'r',encoding='utf8') as f:\n",
    "                l = f.readlines()\n",
    "            with open(os.path.join(corpus_dir,'marked{}'.format(s)),'a',encoding='utf8') as f:\n",
    "                for demo_sent in l:\n",
    "                    if demo_sent:\n",
    "                        demo_sent = list(demo_sent.strip())\n",
    "                        demo_data = [(demo_sent, ['O'] * len(demo_sent))]\n",
    "                        tag = model.demo_one(sess, demo_data)\n",
    "                        count = 0\n",
    "                        mark = 0\n",
    "                        for i in range(len(tag)):\n",
    "                            if tag[i] == 0:\n",
    "                                tag[i] = 'O'\n",
    "                            if mark == 0:\n",
    "                                if tag[i].startswith('B'):\n",
    "                                    if i != 0 and tag[i-1]=='O':\n",
    "                                        demo_sent.insert(i+count,'/o')\n",
    "                                        count += 1\n",
    "                                        mark = 1\n",
    "                            elif mark == 1:\n",
    "                                if tag[i].startswith('B'):\n",
    "                                    demo_sent.insert(i+count,'/{}'.format(tag[i-1][2:].lower()))\n",
    "                                    count += 1\n",
    "                                elif tag[i].startswith('O'):\n",
    "                                    demo_sent.insert(i+count,'/{}'.format(tag[i-1][2:].lower()))\n",
    "                                    count += 1\n",
    "                                    mark = 0\n",
    "                        f.write(''.join(demo_sent)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('.', 'data_path', 'test_data')\n",
    "test_data = read_corpus(test_path)\n",
    "test_size = len(test_data)\n",
    "\n",
    "## testing model\n",
    "# elif args.mode == 'test':\n",
    "#     ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "#     print(ckpt_file)\n",
    "#     paths['model_path'] = ckpt_file\n",
    "#     model = BiLSTM_CRF(args, embeddings, tag2label, word2id, paths, config=config)\n",
    "#     model.build_graph()\n",
    "#     print(\"test data: {}\".format(test_size))\n",
    "#     model.test(test_data)\n",
    "## testing model\n",
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF(embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()\n",
    "print(\"test data: {}\".format(test_size))\n",
    "model.test(test_data)\n",
    "\n",
    "model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
