{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, time, random\n",
    "from utils import str2bool, get_logger, get_entity, get_entitys,get_x_entity\n",
    "from data import random_embedding,tag2label\n",
    "import datapreprocessing as dp\n",
    "from model import BiLSTM_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Session configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # default: 0\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.2  # need ~700MB GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## paths setting\n",
    "paths = {}\n",
    "timestamp='1529463214'\n",
    "output_path = os.path.join('.', 'data_path'+\"_save\", timestamp)\n",
    "if not os.path.exists(output_path): os.makedirs(output_path)\n",
    "summary_path = os.path.join(output_path, \"summaries\")\n",
    "paths['summary_path'] = summary_path\n",
    "if not os.path.exists(summary_path): os.makedirs(summary_path)\n",
    "model_path = os.path.join(output_path, \"checkpoints/\")\n",
    "if not os.path.exists(model_path): os.makedirs(model_path)\n",
    "ckpt_prefix = os.path.join(model_path, \"model\")\n",
    "paths['model_path'] = ckpt_prefix\n",
    "result_path = os.path.join(output_path, \"results\")\n",
    "paths['result_path'] = result_path\n",
    "if not os.path.exists(result_path): os.makedirs(result_path)\n",
    "log_path = os.path.join(result_path, \"log.txt\")\n",
    "paths['log_path'] = log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size: 1234\n"
     ]
    }
   ],
   "source": [
    "## get char embeddings\n",
    "word2id = dp.loadVocab('word2id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load('pretrain_embedding.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= demo =============\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please input your sentence:\n",
      "患者三周无明显诱因下出现心悸、胸闷，无胸痛、气急等不适，面色黧黑，胃纳可，二便调，夜寐安。\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 'B-ZS', 'I-ZS', 0, 'B-ZS', 'I-ZS', 0, 0, 'B-1ZS', 'I-1ZS', 0, 'B-1ZS', 'I-1ZS', 0, 0, 0, 0, 'B-YC', 'I-YC', 'I-YC', 'I-YC', 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ZS: ['心悸', '胸闷']\n",
      "['心悸', '胸闷']\n",
      "{'1b': [], '1jc': [], '1jx': [], '1m': [], '1o': [], '1qt': [], '1s': [], '1t': [], '1w': [], '1x': [], '1yc': [], '1yw': [], '1zl': [], '1zs': ['胸痛', '气急'], '2b': [], '2jc': [], '2jx': [], '2m': [], '2o': [], '2qt': [], '2s': [], '2t': [], '2w': [], '2x': [], '2yc': [], '2yw': [], '2zl': [], '2zs': [], '3b': [], '3jc': [], '3jx': [], '3m': [], '3o': [], '3qt': [], '3s': [], '3t': [], '3w': [], '3x': [], '3yc': [], '3yw': [], '3zl': [], '3zs': [], '4b': [], '4jc': [], '4jx': [], '4m': [], '4o': [], '4qt': [], '4s': [], '4t': [], '4w': [], '4x': [], '4yc': [], '4yw': [], '4zl': [], '4zs': [], '5b': [], '5jc': [], '5jx': [], '5m': [], '5o': [], '5qt': [], '5s': [], '5t': [], '5w': [], '5x': [], '5yc': [], '5yw': [], '5zl': [], '5zs': [], '6b': [], '6jc': [], '6jx': [], '6m': [], '6o': [], '6qt': [], '6s': [], '6t': [], '6w': [], '6x': [], '6yc': [], '6yw': [], '6zl': [], '6zs': [], '7b': [], '7jc': [], '7jx': [], '7m': [], '7o': [], '7qt': [], '7s': [], '7t': [], '7w': [], '7x': [], '7yc': [], '7yw': [], '7zl': [], '7zs': [], 'b': [], 'jc': [], 'jx': [], 'm': [], 'o': [], 'qt': [], 's': [], 't': [], 'w': [], 'x': [], 'yc': ['面色黧黑'], 'yw': [], 'zl': [], 'zs': ['心悸', '胸闷']}\n",
      "Please input your sentence:\n"
     ]
    }
   ],
   "source": [
    "## demo\n",
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF(embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session(config=config) as sess:\n",
    "    print('============= demo =============')\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    while(1):\n",
    "        print('Please input your sentence:')\n",
    "        demo_sent = input()\n",
    "        if demo_sent == '' or demo_sent.isspace():\n",
    "            print('See you next time!')\n",
    "            break\n",
    "        else:\n",
    "            demo_sent = list(demo_sent.strip())\n",
    "            demo_data = [(demo_sent, ['O'] * len(demo_sent))]\n",
    "            tag = model.demo_one(sess, demo_data)\n",
    "            print(tag)\n",
    "            ZS = get_entity(tag, demo_sent)\n",
    "            print('ZS: {}'.format(ZS))\n",
    "            print(get_x_entity('zs',tag, demo_sent))\n",
    "            d = get_entitys(list(dp.tags),tag, demo_sent)\n",
    "            print(d)\n",
    "#             PER, LOC, ORG = get_entity(tag, demo_sent)\n",
    "#             print('PER: {}\\nLOC: {}\\nORG: {}'.format(PER, LOC, ORG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= demo =============\n",
      "INFO:tensorflow:Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring parameters from .\\data_path_save\\1529463214\\checkpoints/model-1200\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=config) as sess:\n",
    "    print('============= demo =============')\n",
    "    saver.restore(sess, ckpt_file)\n",
    "    corpus_dir = 'D:\\\\Desktop\\\\产品\\\\辅诊\\\\cndata\\\\ru1_tb_cis_mzdzbl\\\\tt'\n",
    "    for s in os.listdir(corpus_dir):\n",
    "        if s.endswith('.csv'):\n",
    "            with open(os.path.join(corpus_dir,s),'r',encoding='utf8') as f:\n",
    "                l = f.readlines()\n",
    "            with open(os.path.join(corpus_dir,'marked{}'.format(s)),'a',encoding='utf8') as f:\n",
    "                for demo_sent in l:\n",
    "                    if demo_sent:\n",
    "                        demo_sent = list(demo_sent.strip())\n",
    "                        demo_data = [(demo_sent, ['O'] * len(demo_sent))]\n",
    "                        tag = model.demo_one(sess, demo_data)\n",
    "                        count = 0\n",
    "                        mark = 0\n",
    "                        for i in range(len(tag)):\n",
    "                            if tag[i] == 0:\n",
    "                                tag[i] = 'O'\n",
    "                            if mark == 0:\n",
    "                                if tag[i].startswith('B'):\n",
    "                                    if i != 0 and tag[i-1]=='O':\n",
    "                                        demo_sent.insert(i+count,'/o')\n",
    "                                        count += 1\n",
    "                                        mark = 1\n",
    "                            elif mark == 1:\n",
    "                                if tag[i].startswith('B'):\n",
    "                                    demo_sent.insert(i+count,'/{}'.format(tag[i-1][2:].lower()))\n",
    "                                    count += 1\n",
    "                                elif tag[i].startswith('O'):\n",
    "                                    demo_sent.insert(i+count,'/{}'.format(tag[i-1][2:].lower()))\n",
    "                                    count += 1\n",
    "                                    mark = 0\n",
    "                        f.write(''.join(demo_sent)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.path.join('.', 'data_path', 'test_data')\n",
    "test_data = read_corpus(test_path)\n",
    "test_size = len(test_data)\n",
    "\n",
    "## testing model\n",
    "# elif args.mode == 'test':\n",
    "#     ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "#     print(ckpt_file)\n",
    "#     paths['model_path'] = ckpt_file\n",
    "#     model = BiLSTM_CRF(args, embeddings, tag2label, word2id, paths, config=config)\n",
    "#     model.build_graph()\n",
    "#     print(\"test data: {}\".format(test_size))\n",
    "#     model.test(test_data)\n",
    "## testing model\n",
    "ckpt_file = tf.train.latest_checkpoint(model_path)\n",
    "print(ckpt_file)\n",
    "paths['model_path'] = ckpt_file\n",
    "model = BiLSTM_CRF(embeddings, tag2label, word2id, paths, config=config)\n",
    "model.build_graph()\n",
    "print(\"test data: {}\".format(test_size))\n",
    "model.test(test_data)\n",
    "\n",
    "model_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
